* Algorithm
  * A procedure for solving a computational problem (ex: sorting a set of integers) in a finite number of steps. 
  * More specifically: a step-by-step procedure for solving a problem or accomplishing something (especially using a computer).
  * Definition: logic process to solve computational problems.
    * A procedure for solving a computational problem in a finite number of steps
* Solving a computational problem
  * Problem definition & specification
    * Specify input, output, and constraints
  * Algorithm analysis & design
    * Devise a correct & efficient algorithm
  * Implementation planning
  * Coding, testing and verification 
  * Input → algorithm → output 
  * What's the input/output than algorithm will process it in an efficient way then gives output
* Examples
  * RSA
    * Cryptography
    * Banks use it
  * Quicksort
    * Database
    * (one of the top 10 algorithms so know it well)
  * FFT
    * Signal processing
    * (very important algorithm)
    * Fast F… Transform
    * May not be covered here
  * Huffman 
    * Data compression
    * Supposed to be in data structures class 
  * *make spreadsheet/ notes on all algorithms leaned 
  * Network flow.
    * Routing internet packets.
    * Is in advanced algorithms class
  * Linear programming
    * Planning, decision-making
    * Is in advanced algorithms class
* What is CS435/535
  * Learn well-known algorithms and the design and analysis of algorithms
    * Examine interesting problems
    * Devise algorithms for solving them
    * Data structures and core algorithms
    * Analyze running time of programs
    * Critical thinking
  * Chapter 0: prologue
  * Chapter 1: algorithms with number
  * Chapter 2: divide-and-conquer algorithms
  * Chapter 3: decompositions of graphs
  * Chapter 4: paths in graphs
  * Chapter 5: greedy algorithms
  * Chapter 6: dynamic programming
  * Chapter 7: linear programming 
  * Chapter 8: NP-complete problems
  * Chapter 9: coping with NP-completeness
  * Not covering ch 7 and only briefly covering ch 9 
  * Learn how to critically think to solve problems

Ch 0: Big-O notation
* Asymptotic complexity
  * Running time of an algorithm as a function of input size n for large n
  * Expressed using only the highest-order term in the expression for the exact running time 
    * Instead of exact running time, say (n2)
  * Describes behavior of function in the limit
  * Written using asymptotic notation
  * Language used to describe complexity of a problem if it grows rapidly or slowly
* Asymptotic notation
  * omega,O,alpha,o,w
  * Defined for functions over the natural numbers.
    * Ex: f(n)=omega(n^2)
    * Describes how f(n)grows in comparison to n^2
  * Define a set of functions; in practice used to compare two function sizes
  * The notation (,O,,o,) describe different rate-of-growth relations between the defining function and the defined set of functions.
  * Review the other bigs form data structures
  * Mostly the first three: ,O,
    * Last two o,are more analisis 
    * Need to know first three very well 
* O-notation
  * For function g(n),we define O(g(n)), big-O of n, as the set:
    ________________
    O(g(n))={f(n) : 
    positive constant c and n0
    such that nn0,
    we have 0f(n)cg(n) }
    ____________________
	
      * { means the set of 
      * : means if it satisfies this → 
      * cis a positive constant greater than zero
      * Has to be true for large nnot for all n,we don’t care how it behaves when nis small
    * "=" is not equal but says it is a member of that set
  * Intuitively: set of all functions whose rate of growth is the same as or lower than that of g(n)
		________________________
    Technically, f(n)O(g(n)).
    Older usage, f(n)=O(g(n)).
    _________________________

  * g(n)is an asymptotic upper bound for f(n).

    * Chart
      * f(n)is the runtime
        * If it's always below cg(n)then it has a O(g(n))
        * Below another function times some constant c
        * g(n)should be a function we know very well like linear time
        * So f(n)=O(g(n))
          * If g(n)=n2then f(n)=O(n2)
  * Upper bound of function runtime
    * Worst or average case is O-notation
  * Selection sort is O(n2)
    * If on your machine its 4n2it still is O(n2)drop the constant c
      * 0<=4n^2<=cn^2
        * If you can find a cto be true for large nto be true than we can justify it
          * ccan be anything greater than 4 or equal to 4
            * We don't have to find the exact number of the constant just that it exists
      * 4n^2+3n<=cn^2
      * 4n^2+3n<=4n^2+3n^2
      * 4n^2+3n<=7n^2  true!
        * c is a constant and is true
        * 0<=f(n)<=cg(n)
    * E”is element of”
    * EBackwords”does exist” or “there exists:
      * Not EBackwords
    * AUpsidwon”for all”
    * f(n)"<="g(n)
      * Big O is kind of like <= but not exactly 
* Examples
________________________________________________________
O(g(n))={f(n) : positive constants c and n_0, 
such that AUpsidpwm n>=n_0, we have 0 <= f(n) <= cg(n) }
_________________________________________________________

  * O(n^2)
    * n^2+1
      * n^2+1=O(n^2)
      * Justify
        * n^2+1<=n^2+n^2(when n>=1)
        * n^2+1<=2n^2 ,An>=1
          * c=2
          * n_0=1
    * n^2+n
    * 1000n^2+1000n
    * n^1.999
    * n^2/log n
    * n^2/log log log n
  * 3n=O(n^2)	
    * 3n<=n^2 is true for An>=1
    * Or 3n<=3n^2, An>=11
      * True
    * But to have better understanding of the function find a lower bound to represent the function 
      * But it is true
  * (selection sort is a greedy approach)
  * Selection sort 
    * To sort a million 
      * 1 minute to go through 106(is a million)
      * But we need 2*106to sort through 
        * Will take 4 minutes
      * It is O(n^2) time
      * Need to know if it takes 2 minutes or 4 so you know if there is a bug or not
        * It should take 4 minutes
          * f(n)=cn^2
          * f(10^6)=c(10^6)^2=1min
          * f(2*10^6)=c*4*(10^6)^2
            * =4*c(10^6)^2
            * Equals 4(1 min) = 4 min
* alpha-notation
  * For function g(n), we define alpha(g(n)),big-Omega of n,as the set:
___________________________________
alpha(g(n))={f(n):
ENot positive constants c and n_0,
such that An>=n_0,
we have 0<=cg(n)<=f(n) }
____________________________________

  * Intuitively: Set of all functions whose rate of growth is the same as or higher than that of g(n).
    * g(n)is an asymptotic lower bound for f(n)
  * big-Omega: instead of upper bound it is the lower bound prove it is greater than or equal to. 
* Example 
____________________________________________________
alpha(g(n))={f(n): positive constants c and n0, such 
that An>=n_0, we have 0<=cg(n)<=f(n) }
_____________________________________________________

    * sqrt(n)=alpha(log n).choose cand n_0.
    * 1000n^2+100n
    * 1000n^2-1000n
    * n^3
    * n^2.00001
    * n^2log log log n
    * 2^2^n
